---
title: "FakeAudioDiscriminator"
author: "Santiago Eliges"
date: "2025-08-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
source("tesis-FPCAconFData.R")
source("FDLogRegQuadGDEscabias.R")
```

# Librerías y Configuración Inicial

```{r}
# Instalar paquetes necesarios (si no están instalados)
if (!require("fda")) install.packages("fda")
if (!require("MASS")) install.packages("MASS")
if (!require("pROC")) install.packages("pROC")
library(pROC)
library(fda)
library(MASS)
library(tuneR)
library(seewave)
```

# Pre-proceso de datos
LINK de dataset: https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset

Los datos tomados para este modelo son audios cortos de longitud variable (2 a 10 segs aprox) de fragmentos de audios reales (cortados aparentemente de manera aleatoria) sin balancear por géneros y una misma cantidad de adios falsos generados con modelos de deepfake; "The dataset aggregates data from the latest TTS solutions (such as Deep Voice 3 and Google Wavenet TTS) as well as a variety of real human speech, including the Arctic Dataset (http://festvox.org/cmu_arctic/), LJSpeech Dataset (https://keithito.com/LJ-Speech-Dataset/), VoxForge Dataset (http://www.voxforge.org) and our own speech recordings."

Voy a tomar los audios .mp3 y los transformo en sus correspondientes log-periodogramas.
Luego, voy a transformar a los log-periodogramas en functional data objects con la base de fouerier. 


La mayor crítica que podría hacer es que esto es masomenos como realizar la transformada de bspline para tomar el periodograma y luego vuelvo a hacer una especie de transformación de bspline cuando transformo en un functional data object en la base de bspline, por lo que la interpretación del espacio puede ser poco intuitiva
```{r}


```

```{r}
# Leer un archivo .wav
audio2 <- readWave("D:/Tesis/archive/archive/for-2sec/for-2seconds/testing/real/file10.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav")


mono_audio <- mono(audio2, "left")
signal_real <- mono_audio@left
fs <- mono_audio@samp.rate

t <- seq(0, 2, length.out = length(signal_real))  # dominio temporal real
rangeval <- c(0, 2)

Lcoef <- c(3)
harmacclLdf <- vec2Lfd(Lcoef, rangeval)

estimationBasis <- create.bspline.basis(rangeval = rangeval, nbasis = 100)
fdPar_obj <- fdPar(estimationBasis, Lfdobj = harmacclLdf)

plot(t, signal_real, type = "l",
      ylab = "Log-potencia")

# Compute smooth basis coefficients 
a <- fd2coef(as.matrix(signal_real), estimationBasis)

# Recover smooth functional data
fd_train <- coef2fd(a, estimationBasis) 

#fd_train <- smooth.basis(argvals = t, y = as.matrix(signal_real), fdPar_obj)$fd
fd_train_centered <- center.fd(fd_train)

plot(fd_train)
```



```{r}
# Submuestreo: tomar 1 de cada 10 puntos
sub_factor <- 10
signal_sub <- signal_real[seq(1, length(signal_real), by = sub_factor)]
t_sub <- t[seq(1, length(t), by = sub_factor)]

# Repetimos el proceso con los datos reducidos
fd_train <- smooth.basis(argvals = t_sub, 
                         y = as.matrix(signal_sub), 
                         fdPar_obj)$fd

fd_train_centered <- center.fd(fd_train)

# Graficar señal original y la reducida
par(mfrow=c(2,1))
plot(t, signal_real, type = "l", main = "Señal original (32000 puntos)")
plot(t_sub, signal_sub, type = "l", main = "Señal submuestreada (3200 puntos)")
plot(fd_train)

```


```{r}

audio1 <- readWave("D:/Tesis/archive/archive/for-2sec/for-2seconds/testing/fake/file19.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav")

mono_audio <- mono(audio1, "left")
signal_true <- mono_audio@left
fs <- mono_audio@samp.rate

plot(signal_true, type = "l")



# Transformar los conjuntos a funciones
fd_train <- smooth.basis(argvals = t, y = as.matrix(signal_true), fdPar_obj)$fd
fd_train_centered <- center.fd(fd_train)

plot(fd_train)

```


```{r}

 carpeta_training <- 'archive/for-2sec/for-2sec/training'
 carpeta_training_fake <- 'archive/archive/for-2sec/for-2seconds/training/fake'
 carpeta_training_real <- 'archive/archive/for-2sec/for-2seconds/training/real'
 
 archivos_training_fake<- list.files(carpeta_training_fake, pattern = "\\.wav$", full.names = TRUE)
 archivos_training_real<- list.files(carpeta_training_real, pattern = "\\.wav$", full.names = TRUE)
 
 archivos_training_fake <- archivos_training_fake[1:1000]
 archivos_training_real <- archivos_training_real[1:length(archivos_training_fake)]
 
```
 

# ```{r}
# n_freqs <- t
# # Lista para guardar los vectores
# lista_signals_training_fake <- list()
# nombres_training_fake <- c()
# 
# for (archivo in archivos_training_fake) {
#   audio <- readWave(archivo)
#   audio_mono <- mono(audio, "left")
#   signal <- audio_mono@left
# 
#   lista_signals_training_fake[[length(lista_signals_training_fake) + 1]] <- signal
#   nombres_training_fake <- c(nombres_training_fake, basename(archivo))
# }
# # Convertir lista a data.frame
# df_signals_training_fake <- as.data.frame(do.call(rbind, lista_signals_training_fake))
# rownames(df_signals_training_fake) <- nombres_training_fake
#
#```

```{r}

sub_factor <- 10
t_sub <- t[seq(1, length(t), by = sub_factor)]

# Lista para guardar los vectores
lista_signals_training_fake <- list()
nombres_training_fake <- c()

for (archivo in archivos_training_fake) {
  audio <- readWave(archivo)
  audio_mono <- mono(audio, "left")
  signal <- audio_mono@left

  lista_signals_training_fake[[length(lista_signals_training_fake) + 1]] <- signal[seq(1, length(signal_real), by = sub_factor)]
  nombres_training_fake <- c(nombres_training_fake, basename(archivo))
}
# Convertir lista a data.frame
df_signals_training_fake <- as.data.frame(do.call(rbind, lista_signals_training_fake))
rownames(df_signals_training_fake) <- nombres_training_fake

```


```{r}
# n_freqs <- t
# # Lista para guardar los vectores
# lista_signals_training_real <- vector("list", length(archivos_training_real))
# nombres_training_real <- rep(0, length(archivos_training_real))
# 
# cont = 1
# for (archivo in archivos_training_real) {
#   audio <- readWave(archivo)
#   audio_mono <- mono(audio, "left")
#   signal <- audio_mono@left
#   
#   lista_signals_training_real[[cont]] <- signal
#   nombres_training_real[cont] <- basename(archivo)
#   cont = cont+1
# }
# # Convertir lista a data.frame
# df_signals_training_real <- as.data.frame(do.call(rbind, lista_signals_training_real))
# rownames(df_signals_training_real) <- nombres_training_real

```

```{r}
# Lista para guardar los vectores
lista_signals_training_real <- vector("list", length(archivos_training_real))
nombres_training_real <- rep(0, length(archivos_training_real))

cont = 1
for (archivo in archivos_training_real) {
  audio <- readWave(archivo)
  audio_mono <- mono(audio, "left")
  signal <- audio_mono@left
  
  lista_signals_training_real[[cont]] <- signal[seq(1, length(signal_real), by = sub_factor)]
  nombres_training_real[cont] <- basename(archivo)
  cont = cont+1
}
# Convertir lista a data.frame
df_signals_training_real <- as.data.frame(do.call(rbind, lista_signals_training_real))
rownames(df_signals_training_real) <- nombres_training_real

```


```{r}
# 1. Agregar columna de clase
df_signals_training_fake$clase <- 1
df_signals_training_real$clase <- 0

# 2. Unir dataframes
df_completo_training <- rbind(df_signals_training_fake, df_signals_training_real)
```

# Preparo datos e training y pego un vistazo general sobre las diferencias a grandes razgos entre los audios fake y los reales con las FPCA

```{r}

nbasis <- 900
Lcoef <- c(3)
harmacclLdf = vec2Lfd(Lcoef, rangeval)
estimationBasis = create.bspline.basis(rangeval = rangeval, nbasis = nbasis,norder = 5)
fdPar_obj <- fdPar(estimationBasis, Lfdobj = harmacclLdf )


library(dplyr)
X_train <- df_completo_training %>% select(-clase)


# Transformar los conjuntos a funciones
fd_train <- smooth.basis(argvals = t_sub, y = t(X_train), fdPar_obj)$fd
fd_train_centered <- center.fd(fd_train)

#plot(fd_train)

```

```{r}
X_train_fake <- df_signals_training_fake %>% select(-clase)
fd_train_fake <- smooth.basis(argvals = t_sub, y = t(X_train_fake), fdPar_obj)$fd
fpca_fake <- pca.fd(fd_train_fake, nharm = 3)
#plot(fpca_fake)

X_train_real <- df_signals_training_real %>% select(-clase)
fd_train_real <- smooth.basis(argvals = t_sub, y = t(X_train_real), fdPar_obj)$fd
fpca_real <- pca.fd(fd_train_real, nharm = 3)
#plot(fpca_real)

```
## IDEM EVALUACION
```{r}
carpeta_testing <- 'archive/for-2sec/for-2sec/testing'
carpeta_testing_fake <- 'archive/archive/for-2sec/for-2seconds/testing/fake'
carpeta_testing_real <- 'archive/archive/for-2sec/for-2seconds/testing/real'

archivos_testing_fake<- list.files(carpeta_testing_fake, pattern = "\\.wav$", full.names = TRUE)
archivos_testing_real<- list.files(carpeta_testing_real, pattern = "\\.wav$", full.names = TRUE)

archivos_testing_fake <- head(archivos_testing_fake, 500)
archivos_testing_real <- head(archivos_testing_real, length(archivos_testing_fake))


```



```{r}
# Lista para guardar los vectores
lista_signals_testing_fake <- list()
nombres_testing_fake <- c()

cont <- 1
for (archivo in archivos_testing_fake) {
  if (is.na(archivo)) next
  
  audio <- readWave(archivo)
  audio_mono <- mono(audio, "left")
  signal <- audio_mono@left
  
  lista_signals_testing_fake[[cont]] <- signal[seq(1, length(signal), by = sub_factor)]
  nombres_testing_fake[cont] <- basename(archivo)
  cont = cont+1
}

# Convertir lista a data.frame
df_testing_fake <- as.data.frame(do.call(rbind, lista_signals_testing_fake))
rownames(df_testing_fake) <- nombres_testing_fake

```


```{r}

# Lista para guardar los vectores
lista_signals_testing_real <- list()
nombres_testing_real <- c()

cont <- 1
for (archivo in archivos_testing_real) {
  if (is.na(archivo)) next
  
  audio <- readWave(archivo)
  audio_mono <- mono(audio, "left")
  signal <- audio_mono@left
  
  lista_signals_testing_real[[cont]] <- signal[seq(1, length(signal), by = sub_factor)]
  nombres_testing_real[cont] <- basename(archivo)
  cont = cont+1
}

# Convertir lista a data.frame
df_testing_real <- as.data.frame(do.call(rbind, lista_signals_testing_real))
rownames(df_testing_real) <- nombres_testing_real


```

```{r}
# 1. Agregar columna de clase
df_testing_fake$clase <- 1
df_testing_real$clase <- 0

# 2. Unir dataframes
df_completo_testing <- rbind(df_testing_fake, df_testing_real)
```


```{r}

nbasis <- 900
Lcoef <- c(3)
harmacclLdf = vec2Lfd(Lcoef, rangeval)
fdPar_obj <- fdPar(estimationBasis, Lfdobj = harmacclLdf)


X_testing <- df_completo_testing %>% select(-clase)
y_testing <- df_completo_testing$clase

# Transformar los conjuntos a funciones
fd_testing <- smooth.basis(argvals = t_sub, y = t(X_testing), fdPar_obj)$fd
fd_testing_centered <- center.fd(fd_testing)

plot(fd_testing)

```

# ENTRENAMIENTO
Voy a entrenar los modelos FPCA, sin PCA, FPLRS-lineal y FPLRS-cuadratico usando parametros que encontre medio ojimetro.

```{r, results='hide'}
roughtnessPenalty =list(ldfobj = 3,
modelo_quad = TRUE,
step_gradient = 1e-6,
lambda_lin = 0,
lambda_quad =  0,
iterations = 4000,
tol = 1e-10)

modelofpca_penalized <- fit_models_FPCA_regression (
    X= fd_train_centered,
    Y= df_completo_training$clase,
    t_grid=t_sub,
    var_threshold=0.8,
    alpha=0,
    roughtnessPenalty = roughtnessPenalty,
    crossValglmnet = FALSE,
    variableSelectionMethod = "none"
)



plot(modelofpca_penalized$fit_quad$cost_history, type = "l", lwd = 2, col = "blue",
     xlab = "Iteraciones", ylab = "Negative Log-Likelihood",
     main = "Convergencia del descenso por gradiente")

basis_fpca <- pca.fd(fdobj = fd_train, nharm = modelofpca_penalized$p, centerfns = TRUE) 
eval_fd_basis <- eval.fd(evalarg = t, fdobj= basis_fpca$harmonics)

beta_est_pca_lin <- eval_fd_basis %*% modelofpca_penalized$fit_lin$beta
beta_est_pca_quad <- eval_fd_basis %*% modelofpca_penalized$fit_quad$beta


gamma_est_pca_lin <- eval_fd_basis %*% modelofpca_penalized$fit_lin$gamma %*% t(eval_fd_basis )
gamma_est_pca_quad <- eval_fd_basis %*% modelofpca_penalized$fit_quad$gamma %*% t(eval_fd_basis )
# 
# exportar_plot_beta_full(
#   t_grid        = t,
#   beta_hat_lin  = beta_est_pca_lin,
#   beta_hat_quad = beta_est_pca_quad,
#   #title_suffix  = paste0(scenario_name, " (p=", p, ")")
# )
# 
# exportar_plot_gamma_contour_full(
#   t_grid         = t,
#   gamma_hat_lin  = gamma_est_pca_lin,
#   gamma_hat_quad = gamma_est_pca_quad,
#   #title_suffix   = paste0(scenario_name, " (p=", p, ")")
# )
# 
# exportar_plot_gamma_3d_full(
#   t_grid         = t,
#   gamma_hat_quad = gamma_est_pca_quad,
#   #title_suffix   = paste0(scenario_name, " (p=", p, ")")
# )
# 


eig <- eigen(psi)
psi_half <- eig$vectors %*% diag(sqrt(eig$values)) %*% t(eig$vectors)
matriz_diseño_fpca <- t(fd_train$coefs) %*% psi_half
pca_fpca <- prcomp(matriz_diseño_fpca)
beta_est_fpca <- pca_fpca$rotation[,1:modelofpca_penalized$p] %*% modelofpca_penalized$fit_quad$beta
gamma_est_fpca <- pca_fpca$rotation[,1:modelofpca_penalized$p] %*% modelofpca_penalized$fit_quad$gamma %*% t(pca_fpca$rotation[,1:modelofpca_penalized$p])
mseb_quad_fpca_penalized  <- MSEB(0, modelofpca_penalized$fit_quad$alpha, coef_beta,beta_est_fpca, coef_gamma, gamma_est_fpca)
print(paste("MBSE gamma: ", mseb_quad_fpca_penalized))

predecir_probabilidades_validacion_en_base_fpca <- function(res, fd_valid_centered, estimationBasis) {
  change_basis <- inprod(fd_valid_centered$basis, estimationBasis)  

  A_valid <- t(fd_valid_centered$coefs)
  A_psi_valid <- A_valid %*%  change_basis
  
  beta <- res$beta
  gamma <- res$gamma
  alpha <- res$alpha

  lin_pred <- as.vector(A_psi_valid %*% beta)
  quad_pred <- rowSums((A_psi_valid %*% gamma) * A_psi_valid)
  y_prob_valid <- 1 / (1 + exp(-(alpha + lin_pred + quad_pred)))
return(y_prob_valid)
}


# Probabilidades de validación
basis_fpca <- pca.fd(fdobj = fd_train, nharm = nrow(modelofpca_penalized$fit_quad$beta), centerfns = TRUE) 

y_prob_valid_pca_quad    <- predecir_probabilidades_validacion_en_base_fpca(modelofpca_penalized$fit_quad, fd_testing_centered, basis_fpca$harmonics)
y_prob_valid_pca_lin    <- predecir_probabilidades_validacion_en_base_fpca(modelofpca_penalized$fit_lin, fd_testing_centered, basis_fpca$harmonics)

roc_pca_quad    <- roc(response = y_testing, predictor = y_prob_valid_pca_quad)
roc_pca_lin    <- roc(response = y_testing, predictor = y_prob_valid_pca_lin)


auc_pca_quad    <- auc(roc_pca_quad)
auc_pca_lin    <- auc(roc_pca_lin)

# Imprimir AUROCs
cat("AUROC con PCA:        ", round(auc_pca_quad, 4), "\n")
plot(roc_pca_quad,    col = "darkred", lwd = 2, main = "Curvas ROC - Validación", legacy.axes = TRUE)
lines(roc_pca_lin, col = "darkblue",   lwd = 2, lty = 2)
legend("bottomright",
       legend = c(
         paste0("Cuadratico (AUC = ", round(auc_pca_quad, 4), ")"),
          paste0("Lineal (AUC = ", round(auc_pca_lin, 4), ")")
         )
       ,
       col = c("darkred","darkblue"),
       lwd = 2,
       lty = c(1, 2, 3)
       )

```

# ```{r}
# # roughtnessPenalty =list(ldfobj = 3,
# # modelo_quad = TRUE,
# # step_gradient = 0.001,
# # lambda_lin = 1e-7,
# # lambda_quad =  1e-7,
# # iterations = 4000,
# # tol = 1e-8)
# # 
# # modelo <- fit_models_FPCA_regression(                X = fd_train_centered,
# #                                                      Y = df_completo_training$clase ,
# #                                                      t_grid =  t_sub,
# #                                                      var_threshold = 0.9,
# #                                                      alpha = 1,
# #                                                      variableSelection = "none",
# #                                                      crossValglmnet = FALSE,
# #                                                      #roughtnessPenalty = roughtnessPenalty
# #                                                      )
# # 
# # # plot(modelo$fit_quad$cost_history, type = "l", lwd = 2, col = "blue",
# # #      xlab = "Iteraciones", ylab = "Negative Log-Likelihood",
# # #      main = "Convergencia del descenso por gradiente")
# # 
# # basis_fpca <- pca.fd(fdobj = fd_train_centered, nharm = modelo$p, centerfns = TRUE) 
# # eval_fd_basis <- eval.fd(evalarg = t, fdobj= basis_fpca$harmonics)
# # 
# # params_estimados <- reconstruct_functions(modelo$phi_hat, modelo$p, modelo$fit_lin, modelo$fit_quad, modelo$combos_p, t_sub, fd_train_centered)
# # 
# # beta_est_pca_lin <- params_estimados$beta_hat_lin
# # beta_est_pca_quad <- params_estimados$beta_hat_quad
# # 
# # gamma_est_pca_lin <- params_estimados$gamma_hat_lin
# # gamma_est_pca_quad <- params_estimados$gamma_hat_quad
# # 
# # 
# # 
# # predecir_probabilidades_validacion_en_base_fpca <- function(res, fd_valid_centered, t_grid, estimationBasis) {
# #   eval_fd_valid <- t(eval.fd(t_grid, fd_valid_centered))
# #   
# #   beta <- res$beta
# #   gamma <- res$gamma
# #   alpha <- res$alpha
# # 
# #   lin_pred <- as.vector(eval_fd_valid %*% beta)
# #   quad_pred <- rowSums((eval_fd_valid %*% gamma) * eval_fd_valid)
# #   y_prob_valid <- 1 / (1 + exp(-(alpha + lin_pred + quad_pred)))
# # return(y_prob_valid)
# # }
# # 
# # 
# # # Probabilidades de validación
# # basis_fpca <- pca.fd(fdobj = fd_train_centered, nharm = 900, centerfns = TRUE) 
# # 
# # res_quad <- list(
# #   beta = beta_est_pca_quad,
# #   gamma = gamma_est_pca_quad,
# #   alpha = 0
# # )
# # 
# # res_lin <- list(
# #   beta = beta_est_pca_lin,
# #   gamma = gamma_est_pca_lin,
# #   alpha = 0
# # )
# 
# AAABASIS <- basis_fpca$harmonics
# AAAABETA <- res_quad$beta
# eval_fd_valid <- eval.fd(t_sub, fd_testing)
# 
# 
# y_prob_valid_pca_quad    <- predecir_probabilidades_validacion_en_base_fpca(res_quad, fd_testing_centered, t_sub, basis_fpca$harmonics)
# y_prob_valid_pca_lin    <- predecir_probabilidades_validacion_en_base_fpca(res_lin , fd_testing_centered, t_sub, basis_fpca$harmonics)
# 
# roc_pca_quad    <- roc(response = df_completo_testing$clase, predictor = y_prob_valid_pca_quad)
# roc_pca_lin    <- roc(response = df_completo_testing$clase, predictor = y_prob_valid_pca_lin)
# 
# 
# auc_pca_quad    <- auc(roc_pca_quad)
# auc_pca_lin    <- auc(roc_pca_lin)
# 
# # Imprimir AUROCs
# cat("AUROC con PCA:        ", round(auc_pca_quad, 4), "\n")
# plot(roc_pca_quad,    col = "darkred", lwd = 2, main = "Curvas ROC - Validación", legacy.axes = TRUE)
# lines(roc_pca_lin, col = "darkblue",   lwd = 2, lty = 2)
# legend("bottomright",
#        legend = c(
#          paste0("Cuadratico (AUC = ", round(auc_pca_quad, 4), ")"),
#           paste0("Lineal (AUC = ", round(auc_pca_lin, 4), ")")
#          )
#        ,
#        col = c("darkred","darkblue"),
#        lwd = 2,
#        lty = c(1, 2, 3)
#        )

#```




```{r}


beta_init <- rnorm(nbasis, sd = 0.1)
gamma_init <- gamma_init <- matrix(rnorm(nbasis^2, sd = 0.1), nrow = nbasis)
alpha_init <- 0

fd_train_center <- center.fd(fdobj = fd_train)
Lcoef <- c(3)
harmacclLdf = vec2Lfd(Lcoef, rangeval)

res_pca_quad <- gradient_descent_penalized_PCA(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init, gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.0001, iterations = 2000, var_threshold = 0.9, LdPenalization = harmacclLdf, lambda_lin = 1e-5, lambda_quad = 1e-6)
 res_pca_noquad <- gradient_descent_penalized_PCA(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init, gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.0001, iterations = 2000, var_threshold = 0.9, LdPenalization = harmacclLdf, lambda_lin = 1e-5, lambda_quad = 1e-6,modelo_quad = FALSE)
 
# 
# beta_init <- rnorm(nbasis, sd = 0.1)
# gamma_init <- gamma_init <- matrix(rnorm(nbasis^2, sd = 0.1), nrow = nbasis)
# alpha_init <- 0
# res_noPCA <- gradient_descent_noPCA(fd_centered = fd_train_centered,y = df_completo_training$clase, 
#                                     beta = beta_init,gamma = gamma_init, alpha = alpha_init,
#                                     step_gradient = 0.02, iterations = 1000, basis = estimationBasis,
#                                     LdPenalization = harmacclLdf, lambda_lin = 0, lambda_quad = 1e-3)
# 
# beta_init <- rnorm(nbasis, sd = 0.1)
# gamma_init <- gamma_init <- matrix(rnorm(nbasis^2, sd = 0.1), nrow = nbasis)
# alpha_init <- 0
# res_plsr <- gradient_descent_penalized_plsr(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init,gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.01, iterations = 8000, LdPenalization = harmacclLdf, lambda_lin = 0, lambda_quad = 1e-3)
# 
# 
# res_plsr_noquad <- gradient_descent_penalized_plsr(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init,gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.01, iterations = 8000, LdPenalization = harmacclLdf, lambda_lin = 1e-5, lambda_quad = 1e-3, modelo_quad = FALSE)


```

```{r, results='hide'}
res_plsr <- gradient_descent_penalized_plsr(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init,gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.00001, iterations = 4000, LdPenalization = harmacclLdf, lambda_lin = 1e-8, lambda_quad = 1e-8)


res_plsr_noquad <- gradient_descent_penalized_plsr(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init,gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.0001, iterations = 4000, LdPenalization = harmacclLdf, lambda_lin = 1e-8, lambda_quad = 1e-8, modelo_quad = FALSE)
```

```{r}
res_plsr_2<- FPLSR_2(
    fd_centered=fd_train,
    y= y_train,
    alpha  = 0,
    step_gradient = 0.005,
    iterations = 10000,
    tol = 1e-9,
    basis = basis,
    LdPenalization = harmacclLdf,
    lambda_lin = 0,
    lambda_quad = 0,
    nt_lin = 5,
    nt_quad = 60,
    nivel_significancia_lin = 0.0255, 
    nivel_significancia_quad = 0.0255, 
    scale = TRUE)
```


```{r}
res_noPCA <- gradient_descent_noPCA(fd_centered = fd_train_centered,y = df_completo_training$clase, beta = beta_init,gamma = gamma_init, alpha = alpha_init, basis = estimationBasis, step_gradient = 0.0001, iterations = 4000, LdPenalization = harmacclLdf, lambda_lin = 1e-8, lambda_quad = 1e-8)

```



## EVALUAMOS
Comparo las AU ROC de los modelos, y para el modelo con PLSR comparo con su analogo pero anulando el termino cuaratico para ver qué tanto aporta (spoiler: no parece aportar mucho el término cuadratico)

```{r}


# Probabilidades de validación
y_prob_valid_pca    <- predecir_probabilidades_validacion(res_pca_quad, fd_valid, basis, modo = "PCA")
y_prob_valid_pca_noquad    <- predecir_probabilidades_validacion(res_pca_noquad, fd_valid, basis, modo = "PCA")
y_prob_valid_NoPCA  <- predecir_probabilidades_validacion(res_noPCA, fd_valid, basis, modo = "NoPCA")
y_prob_valid_plsr   <- predecir_probabilidades_validacion(res_plsr, fd_valid, basis, modo = "PLSR")
y_prob_valid_plsr_noquad   <- predecir_probabilidades_validacion(res_plsr_noquad, fd_valid, basis, modo = "PLSR")
y_prob_valid_plsr_2   <- predecir_probabilidades_validacion(res_plsr_2, fd_valid, basis, modo = "PLSR")
y_prob_valid_base_fpca    <- predecir_probabilidades_validacion_en_base_fpca(modelofpca_penalized$fit_quad, fd_valid, basis_fpca$harmonics)
y_prob_valid_base_fpca_noquad    <- predecir_probabilidades_validacion_en_base_fpca(modelofpca_penalized$fit_lin, fd_valid, basis_fpca$harmonics)

roc_pca    <- roc(response = y_valid, predictor = y_prob_valid_pca)
roc_pca_noquad    <- roc(response = y_valid, predictor = y_prob_valid_pca_noquad)
roc_noPCA  <- roc(response = y_valid, predictor = y_prob_valid_NoPCA)
roc_plsr   <- roc(response = y_valid, predictor = y_prob_valid_plsr)
roc_plsr_2   <- roc(response = y_valid, predictor = y_prob_valid_plsr_2)
roc_plsr_noquad   <- roc(response = y_valid, predictor = y_prob_valid_plsr_noquad)
roc_base_fpca  <- roc(response = y_valid, predictor = y_prob_valid_base_fpca)
roc_base_fpca_noquad    <- roc(response = y_valid, predictor = y_prob_valid_base_fpca_noquad)

auc_pca    <- auc(roc_pca)
auc_pca_noquad    <- auc(roc_pca_noquad)
auc_noPCA  <- auc(roc_noPCA)
auc_plsr   <- auc(roc_plsr)
auc_plsr_2   <- auc(roc_plsr_2)
auc_plsr_noquad   <- auc(roc_plsr_noquad)
auc_base_fpca  <- auc(roc_base_fpca)
auc_base_fpca_noquad <- auc(roc_base_fpca_noquad)

# Imprimir AUROCs
cat("AUROC con PCA cuad:        ", round(auc_pca, 4), "\n")
cat("AUROC con PCA lineal:        ", round(auc_pca_noquad, 4), "\n")
cat("AUROC sin PCA:        ", round(auc_noPCA, 4), "\n")
cat("AUROC con PLSR cuad: ", round(auc_plsr, 4), "\n")
cat("AUROC con PLSR lineal: ", round(auc_plsr_noquad, 4), "\n")
cat("AUROC con PLSR_2: ", round(auc_plsr_2, 4), "\n")
cat("AUROC base fpca: ", round(auc_base_fpca, 4), "\n")
cat("AUROC base fpca lineal: ", round(auc_base_fpca_noquad, 4), "\n")

#----- abro para la desscarga ----
# Abrir el dispositivo gráfico
png("plots_fakaudio/curvas_roc_comparacion_modelos.png", width = 800, height = 600, res = 120)


plot(roc_pca,    col = "darkgreen", lwd = 2, main = "Curvas ROC - Validacion", legacy.axes = TRUE)
lines(roc_pca_noquad,    col = "lightgreen", lwd = 2, lty = 3)
lines(roc_noPCA, col = "darkred",   lwd = 2, lty = 1)
lines(roc_plsr,  col = "darkblue",      lwd = 2, lty = 1)
lines(roc_plsr_noquad, col = "skyblue", lwd = 2, lty= 2)
lines(roc_plsr_2, col = "#007999", lwd = 2)
lines(roc_base_fpca, col = "purple", lwd = 2, lty = 1)
lines(roc_base_fpca_noquad, col = "violet", lwd = 2, lty = 2)

legend("bottomright",
       legend = c(
         paste0("(naive) (AUC = ", round(auc_noPCA, 4), ")"),
         paste0("(0) (AUC = ", round(auc_base_fpca, 4), ")"),
         paste0("(0) lineal (AUC = ", round(auc_base_fpca_noquad, 4), ")"),
         paste0("(1) (AUC = ", round(auc_pca, 4), ")"),
         paste0("(1) lineal (AUC = ", round(auc_pca_noquad, 4), ")"),
         paste0("(2) (AUC = ", round(auc_plsr, 4), ")"),
         paste0("(2) lineal (AUC = ", round(auc_plsr_noquad, 4), ")"),
         paste0("PLSR 2 (AUC = ", round(auc_plsr_2, 4), ")")
                ),
       col = c("darkred","purple", "violet", "darkgreen","lightgreen", "darkblue","skyblue", "#007999"),
       lwd = 2,
       lty = c(1, 1, 2, 1 ,2, 1, 2, 1),
       cex = 0.75,                    # reduce tamaño del texto
       bty = "n")

# Cerrar y guardar la imagen
dev.off()

```

```{r}

# --- Función idéntica: sigue calculando probabilidades ---
predecir_probabilidades_validacion <- function(res, fd_valid_centered, estimationBasis, modo = c("PCA", "NoPCA", "PLSR")) {
  modo <- match.arg(modo)
  psi <- inprod(estimationBasis, estimationBasis)

  A_valid <- t(fd_valid_centered$coefs)
  A_psi_valid <- A_valid %*% psi
  
  beta  <- res$beta
  gamma <- res$gamma
  alpha <- res$alpha
  
  lin_pred  <- as.vector(A_psi_valid %*% beta)
  quad_pred <- rowSums((A_psi_valid %*% gamma) * A_psi_valid)
  y_prob_valid <- 1 / (1 + exp(-(alpha + lin_pred + quad_pred)))
  
  return(y_prob_valid)
}

# --- Calcular probabilidades de validación ---
y_prob_valid_pca    <- predecir_probabilidades_validacion(res_pca_quad, fd_valid, basis, modo = "PCA")
y_prob_valid_pca_noquad <- predecir_probabilidades_validacion(res_pca_noquad, fd_valid, basis, modo = "PCA")
y_prob_valid_NoPCA  <- predecir_probabilidades_validacion(res_noPCA, fd_valid, basis, modo = "NoPCA")
y_prob_valid_plsr   <- predecir_probabilidades_validacion(res_plsr, fd_valid, basis, modo = "PLSR")
y_prob_valid_plsr_2   <- predecir_probabilidades_validacion(res_plsr_2, fd_valid, basis, modo = "PLSR")
y_prob_valid_plsr_noquad <- predecir_probabilidades_validacion(res_plsr_noquad, fd_valid, basis, modo = "PLSR")
y_prob_valid_base_fpca <- predecir_probabilidades_validacion_en_base_fpca(modelofpca_penalized$fit_quad, fd_valid, basis_fpca$harmonics)
y_prob_valid_base_fpca_noquad <- predecir_probabilidades_validacion_en_base_fpca(modelofpca_penalized$fit_lin, fd_valid, basis_fpca$harmonics)

# --- Calcular curvas PR (Precision-Recall) ---
# PRROC espera que las etiquetas positivas sean 1 y las negativas 0
get_pr <- function(y_true, y_scores) {
  pos <- y_scores[y_true == 1]
  neg <- y_scores[y_true == 0]
  pr.curve(scores.class0 = pos, scores.class1 = neg, curve = TRUE)
}

pr_pca    <- get_pr(y_valid, y_prob_valid_pca)
pr_pca_noquad <- get_pr(y_valid, y_prob_valid_pca_noquad)
pr_noPCA  <- get_pr(y_valid, y_prob_valid_NoPCA)
pr_plsr   <- get_pr(y_valid, y_prob_valid_plsr)
pr_plsr_2   <- get_pr(y_valid, y_prob_valid_plsr_2)
pr_plsr_noquad <- get_pr(y_valid, y_prob_valid_plsr_noquad)
pr_base_fpca <- get_pr(y_valid, y_prob_valid_base_fpca)
pr_base_fpca_noquad <- get_pr(y_valid, y_prob_valid_base_fpca_noquad)

# --- Extraer AUC-PR ---
auc_pr_pca    <- pr_pca$auc.integral
auc_pr_pca_noquad <- pr_pca_noquad$auc.integral
auc_pr_noPCA  <- pr_noPCA$auc.integral
auc_pr_plsr   <- pr_plsr$auc.integral
auc_pr_plsr_2   <- pr_plsr_2$auc.integral
auc_pr_plsr_noquad <- pr_plsr_noquad$auc.integral
auc_pr_base_fpca <- pr_base_fpca$auc.integral
auc_pr_base_fpca_noquad <- pr_base_fpca_noquad$auc.integral

# --- Imprimir AUC-PR ---
cat("AUC-PR con PCA cuad:        ", round(auc_pr_pca, 4), "\n")
cat("AUC-PR con PCA lineal:      ", round(auc_pr_pca_noquad, 4), "\n")
cat("AUC-PR sin PCA:             ", round(auc_pr_noPCA, 4), "\n")
cat("AUC-PR con PLSR cuad:       ", round(auc_pr_plsr, 4), "\n")
cat("AUC-PR con PLSR 2:       ", round(auc_pr_plsr_2, 4), "\n")
cat("AUC-PR con PLSR lineal:     ", round(auc_pr_plsr_noquad, 4), "\n")
cat("AUC-PR base fpca:           ", round(auc_pr_base_fpca, 4), "\n")
cat("AUC-PR base fpca lineal:    ", round(auc_pr_base_fpca_noquad, 4), "\n")

#----- abro para la desscarga ----
# Abrir el dispositivo gráfico
png("plots_fakeaudio/curvas_pr_comparacion_modelos.png", width = 800, height = 600, res = 120)


# --- Graficar todas las curvas PR ---
plot(pr_pca$curve[,1], pr_pca$curve[,2], type = "l", col = "darkgreen", lwd = 2,
     xlab = "Recall", ylab = "Precision", main = "Curvas PR - Validación",
     ylim = c(0,1), xlim = c(0,1))
lines(pr_pca_noquad$curve[,1], pr_pca_noquad$curve[,2], col = "lightgreen", lwd = 2, lty = 3)
lines(pr_noPCA$curve[,1], pr_noPCA$curve[,2], col = "darkred", lwd = 2)
lines(pr_plsr$curve[,1], pr_plsr$curve[,2], col = "darkblue", lwd = 2)
lines(pr_plsr_noquad$curve[,1], pr_plsr_noquad$curve[,2], col = "skyblue", lwd = 2, lty = 2)
lines(pr_plsr_2$curve[,1], pr_plsr_2$curve[,2], col = "#007999", lwd = 2)
lines(pr_base_fpca$curve[,1], pr_base_fpca$curve[,2], col = "purple", lwd = 2)
lines(pr_base_fpca_noquad$curve[,1], pr_base_fpca_noquad$curve[,2], col = "violet", lwd = 2, lty = 2)

legend("bottomright",
       legend = c(
         paste0("(naive) (AUC = ", round(auc_pr_noPCA, 4), ")"),
         paste0("(0) (AUC = ", round(auc_pr_base_fpca, 4), ")"),
         paste0("(0) lineal (AUC = ", round(auc_pr_base_fpca_noquad, 4), ")"),
         paste0("(1) (AUC = ", round(auc_pr_pca, 4), ")"),
         paste0("(1) lineal (AUC = ", round(auc_pr_pca_noquad, 4), ")"),
         paste0("(2) (AUC = ", round(auc_pr_plsr, 4), ")"),
         paste0("(2) lineal (AUC = ", round(auc_pr_plsr_noquad, 4), ")"),
         paste0("PLSR (AUC = ", round(auc_pr_plsr_2, 4), ")")
                ),
       col = c("darkred","purple", "violet", "darkgreen","lightgreen", "darkblue","skyblue", "#007999"),
       lwd = 2,
       lty = c(1, 1, 2, 1 ,2, 1, 2, 1),
       cex = 0.75,                    # reduce tamaño del texto
       bty = "n")
# Cerrar y guardar la imagen
dev.off()
```



```{r}
# Asegurate de usar los nombres correctos de tus objetos reales.
# Aquí asumo que existen:
# res_pca_quad$beta, res_plsr$beta, res_noPCA$beta, beta_est_fpca, matrix_beta
# gamma_est_pca, gamma_est_plsr, gamma_est_NOpca, gamma_est_fpca, gamma_true

evalbasis <- eval.basis(t, estimationBasis)

# Guardar en listas (manteniendo la estructura original: vectores/matrices)
betas_list <- list(
  PCA   = evalbasis%*%res_pca_quad$beta ,
  PLSR  = evalbasis%*%res_plsr$beta,
  #Naive = evalbasis%*%res_noPCA$beta,
  FPCA  = beta_est_pca_quad
)

gammas_list <- list(
  PCA   = evalbasis %*% res_pca_quad$gamma %*% t(evalbasis),
  PLSR  = evalbasis %*% res_plsr$gamma %*% t(evalbasis),
  #Naive = evalbasis %*% res_noPCA$gamma %*% t(evalbasis),      # fijate este nombre; que coincida con tu variable real
  FPCA  = gamma_est_pca_quad
)

nombres <- names(betas_list)   # toma los nombres de las listas (coherente)

# chequeo rápido de consistencia
if (!all(names(betas_list) == names(gammas_list))) {
  stop("Los nombres/orden de betas_list y gammas_list no coinciden.")
}

# crear carpeta plots si no existe
if (!dir.exists("plots")) dir.create("plots")

for (nm in nombres) {
  # extraer objetos por nombre
  beta_est_obj  <- betas_list[[nm]]
  gamma_est_obj <- gammas_list[[nm]]

  # construir nombres de archivo con paste0
  out_beta  <- file.path("plots_fakeaudio", paste0("beta_est_", nm, "_gscv.png"))
  out_cont  <- file.path("plots_fakeaudio", paste0("contour_gamma_est_", nm, "_gscv.png"))
  out_3d    <- file.path("plots_fakeaudio", paste0("3dplot_gamma_est_", nm, "_gscv.png"))

  # exportar (ajustá los argumentos según lo que esperan tus funciones)
  exportar_plot_beta_full(
    t_grid        = t,
    beta_est      = beta_est_obj,
    output_filename = out_beta,
    title_suffix  = paste0(nm)
  )

  exportar_gamma_contour_full(
    t_grid         = t,
    gamma          = gamma_est_obj,
    output_filename = out_cont,
    title_suffix   = paste0(nm)
  )

  exportar_plot_gamma_3d_full(
    t_grid         = t,
    gamma          = gamma_est_obj,
    output_filename = out_3d,
    title_suffix   = paste0(nm)
  )
}


```
```{r}

dim(res_pca_quad$gamma)

```


```{r}
predecir_probabilidades_validacion <- function(res, fd_valid_centered, estimationBasis, modo = c("PCA", "NoPCA", "PLSR")) {
  modo <- match.arg(modo)
  psi <- inprod(estimationBasis, estimationBasis)

  A_valid <- t(fd_valid_centered$coefs)
  A_psi_valid <- A_valid %*% psi
  
  beta <- res$beta
  gamma <- res$gamma
  alpha <- res$alpha

  lin_pred <- as.vector(A_psi_valid %*% beta)
  quad_pred <- rowSums((A_psi_valid %*% gamma) * A_psi_valid)
  y_prob_valid <- 1 / (1 + exp(-(alpha + lin_pred + quad_pred)))
return(y_prob_valid)
}


# Probabilidades de validación
y_prob_valid_pca    <- predecir_probabilidades_validacion(res,         fd_testing_centered, estimationBasis, modo = "PCA")
# y_prob_valid_NoPCA  <- predecir_probabilidades_validacion(res_noPCA,   fd_testing_centered, estimationBasis, modo = "NoPCA")
y_prob_valid_plsr   <- predecir_probabilidades_validacion(res_plsr,    fd_testing_centered, estimationBasis, modo = "PLSR")
y_prob_valid_plsr_noquad   <- predecir_probabilidades_validacion(res_plsr_noquad,    fd_testing_centered, estimationBasis, modo = "PLSR")


roc_pca    <- roc(response = df_completo_testing$clase, predictor = y_prob_valid_pca)
# roc_noPCA  <- roc(response = df_completo_testing$clase, predictor = y_prob_valid_NoPCA)
roc_plsr   <- roc(response = df_completo_testing$clase, predictor = y_prob_valid_plsr)
roc_plsr_noquad   <- roc(response = df_completo_testing$clase, predictor = y_prob_valid_plsr_noquad)

auc_pca    <- auc(roc_pca)
# auc_noPCA  <- auc(roc_noPCA)
auc_plsr   <- auc(roc_plsr)
auc_plsr_noquad   <- auc(roc_plsr_noquad)


# Imprimir AUROCs
cat("AUROC con PCA:        ", round(auc_pca, 4), "\n")
# cat("AUROC sin PCA:        ", round(auc_noPCA, 4), "\n")
cat("AUROC con PLSR penal: ", round(auc_plsr, 4), "\n")
cat("AUROC con PLSR lineal: ", round(auc_plsr_noquad, 4), "\n")
plot(roc_pca,    col = "darkgreen", lwd = 2, main = "Curvas ROC - Validación", legacy.axes = TRUE)
# lines(roc_noPCA, col = "darkred",   lwd = 2, lty = 2)
lines(roc_plsr,  col = "blue",      lwd = 2, lty = 3)
lines(roc_plsr_noquad, col = "purple", lwd = 2, lty= 4)

legend("bottomright",
       legend = c(
         paste0("Con PCA (AUC = ", round(auc_pca, 4), ")"),
         # paste0("Sin PCA (AUC = ", round(auc_noPCA, 4), ")"),
         paste0("PLSR penalizado (AUC = ", round(auc_plsr, 4), ")"),
         paste0("PLSR penalizado lineal (AUC = ", round(auc_plsr_noquad, 4), ")")

                ),
       col = c("darkgreen", "blue", "purple"),
       lwd = 2,
       lty = c(1, 2, 3, 4))

```
#Reconstrucción de las funciones parametricas estimadas
Reconstruyo con las estimaciones a los parametros $\beta(t), \gamma(t,s)$

## MODELO LRPLSR(QUAD)

```{r}

# Curva de convergencia
plot(res_plsr$cost_history, type = "l", lwd = 2, col = "blue",
     xlab = "Iteraciones", ylab = "Negative Log-Likelihood",
     main = "Convergencia del descenso por gradiente")

plot(fd(coef = res_plsr$beta, basisobj =  estimationBasis),  col = "blue", pch = 1)

evalbasis <- eval.basis(t_sub,estimationBasis, Lfdobj = harmacclLdf)
#evalbasis <- eval.fd(t,basis2)
# Visualizar con persp (superficie 3D base)
gamma_est_plsr <- evalbasis %*% res_plsr$gamma %*% t(evalbasis )

persp(t_sub, t_sub, gamma_est_plsr,
      main = "Superficie Estimada (plsr)",
      theta = 30, phi = 30,
      xlab = "s", ylab = "t", zlab = "gamma(s,t)",
      col = "lightgreen",
      ticktype = "detailed")

image(t_sub, t_sub, gamma_est_plsr, main = "Gamma Estimada(PLSR)", col = heat.colors(20))


psi <- inprod(estimationBasis,estimationBasis)
# Medir accuracy de predicción
y_pred_final <- predict_log_func(fd_centered = fd_testing_centered, psi, res_plsr$beta, res_plsr$gamma, res_plsr$alpha)
y_clasif <- ifelse(y_pred_final > 0.5, 1, 0)
accuracy <- mean(df_completo_testing$clase == y_clasif)
cat("Accuracy final:", round(accuracy, 3), "\n")
```

## MODELO LR PLSR(Lin)

```{r}


plot(fd(coef = res_plsr_noquad$beta, basisobj =  estimationBasis),  col = "blue", pch = 1)

evalbasis <- eval.basis(t_sub,estimationBasis, Lfdobj = harmacclLdf)
#evalbasis <- eval.fd(t,basis2)
# Visualizar con persp (superficie 3D base)
gamma_est_plsr_noquad <- evalbasis %*% res_plsr_noquad$gamma %*% t(evalbasis )

image(t_sub, t_sub, gamma_est_plsr_noquad, main = "Gamma Estimada(plsr no quad)", col = heat.colors(20))


# Medir accuracy de predicción
y_pred_final <- predict_log_func(fd_centered = fd_testing_centered, psi, res_plsr_noquad$beta, res_plsr_noquad$gamma, res_plsr_noquad$alpha)
y_clasif <- ifelse(y_pred_final > 0.5, 1, 0)
accuracy <- mean(df_completo_testing$clase == y_clasif)
cat("Accuracy final:", round(accuracy, 3), "\n")
```



## Modelo FPCA

```{r}


# Curva de convergencia
plot(res$cost_history, type = "l", lwd = 2, col = "blue",
     xlab = "Iteraciones", ylab = "Negative Log-Likelihood",
     main = "Convergencia del descenso por gradiente")


plot(fd(coef = res$beta, basisobj =  estimationBasis),  col = "blue", pch = 1)

evalbasis <- eval.basis(t_sub,estimationBasis, Lfdobj = harmacclLdf)
#evalbasis <- eval.fd(t,basis2)
# Visualizar con persp (superficie 3D base)
gamma_est_fpca <- evalbasis %*% res$gamma %*% t(evalbasis )

persp(t_sub, t_sub, gamma_est_fpca,
      main = "Superficie Estimada (fPCA)",
      theta = 30, phi = 30,
      xlab = "s", ylab = "t", zlab = "gamma(s,t)",
      col = "lightgreen",
      ticktype = "detailed")

image(t_sub, t_sub, gamma_est_fpca, main = "Gamma Estimada(fPCA)", col = heat.colors(20))


# Medir accuracy de predicción
y_pred_final <- predict_log_func(fd_centered = fd_testing_centered, psi, res$beta, res$gamma, res$alpha)
y_clasif <- ifelse(y_pred_final > 0.5, 1, 0)
accuracy <- mean(df_completo_testing$clase == y_clasif)
cat("Accuracy final:", round(accuracy, 3), "\n")
```


